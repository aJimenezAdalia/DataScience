{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a246e81",
   "metadata": {},
   "source": [
    "# UN ESTUDIO SOBRE POSTS EN HACKER NEWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0440f688",
   "metadata": {},
   "source": [
    "En este proyecto, vamos a trabajar con un dataset del conocido sitio de tecnología Hacker News \n",
    "\n",
    "https://news.ycombinator.com/\n",
    "\n",
    "Es un dataset público, en formato .csv, que contiene todos los posts de Hacker News (HN) desde septiembre de 2015 hasta septiembre de 2016.\n",
    "\n",
    "Esta popular web es un sitio de noticias centradas en la tecnología y  el emprendimiento, quizás el más grande del mundo, y es propiedad del fondo de inversión de Paul Graham 'Y Combinator'.\n",
    "\n",
    "Los usuarios de esta web abren hilos de discusión que son votados y comentados, de manera similar a *reddit*. Hacker News (HN) es extremadamente popular en comunidades de tecnología y de startups, y los top posts de HN pueden llegar a tener cientos de miles de visitas.\n",
    "\n",
    "En este estudio nos vamos a centrar en los posts \"Ask HN\" y \"Show HN\".\n",
    "\n",
    "Este tipo de posts son conocidos porque hay muchos de ellos que son muy interesantes. En concreto, los posts que comienzan con Ask HN preguntan algo a los usuarios de HN, mientras que los que comienzan por Show HN enseñan algún tipo de contenido a la comunidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9ca784",
   "metadata": {},
   "source": [
    "Vamos a leer el dataset, y lo vamos a convertir en una lista para poder trabajar con él:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc9ff13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "abrir = open(\"HN_posts_year_to_Sep_26_2016.csv\", encoding = 'utf-8')\n",
    "leer = reader(abrir)\n",
    "hn = list(leer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e8e6ad",
   "metadata": {},
   "source": [
    "En primer lugar, ya con el dataset convertido en una lista de listas (que hemos llamado HN), vamos a visualizar el primer elemento, que presumiblemente será la cabecera de los datos contenidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d22f8bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "print(hn[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505e38f3",
   "metadata": {},
   "source": [
    "Al tratarse de la cabecera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b8f1b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "cabecera = hn[0]\n",
    "print(len(cabecera))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cc0303",
   "metadata": {},
   "source": [
    "Los elementos (posts) del dataset tienen 7 columnas, que contienen los datos mostrados en la cabecera. En concreto:\n",
    "\n",
    "- id: la id única del post\n",
    "- title: el título del post\n",
    "- url: la url del post\n",
    "- num_points: número de puntuaciones del post\n",
    "- num_comments: número de comentarios del post\n",
    "- author: nickname del autor del post\n",
    "- created_at: fecha de creación del post (zona horaria Eastern Time USA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1468bf6",
   "metadata": {},
   "source": [
    "Vamos a visualizar los cinco primeros posts del dataset. \n",
    "Pero antes, y ya que tenemos la cabecera en la variable homónima, vamos a reconvertir nuestro dataset en una nueva lista, pero omitiendo la cabecera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a051566d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'], ['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']]\n"
     ]
    }
   ],
   "source": [
    "hn = hn[1:]\n",
    "print(hn[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a32220c",
   "metadata": {},
   "source": [
    "Vamos a ver la longitud del dataset, que son en realidad el número de post que contiene el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0941e0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293119\n"
     ]
    }
   ],
   "source": [
    "print(len(hn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92bf09d",
   "metadata": {},
   "source": [
    "Por tanto, tenemos casi 300.000 posts de HN en nuestro dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb7a0e5",
   "metadata": {},
   "source": [
    "Al tratarse de todos los posts de un año, habrá muchos de ellos que no tengan relevancia para nosotros. \n",
    "\n",
    "Como comentamos en la introducción, queremos centrarnos en los posts Ask Hn y Show HN, y vamos a filtrar por este tipo de posts.\n",
    "\n",
    "Antes de hacer esto, debemos hacer una serie de comprobaciones en el dataset, para saber que está listo para trabajar con él.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccafe232",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80b34b0",
   "metadata": {},
   "source": [
    "Para empezar, vamos a comprobar si todos los elementos del dataset tienen exactamente 7 subelementos, que es lo que esperamos dada la longitud de la cabecera.\n",
    "\n",
    "Vamos a iterar el dataset completo para buscar errores de longitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d0777b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 293119 elementos con 7 subelementos, y 0 elementos con un número distinto de elementos\n"
     ]
    }
   ],
   "source": [
    "# Creamos dos contadores, uno contará los posts con 7 elementos, el otro los que no:\n",
    "posts_7 = 0\n",
    "post_no7 = 0\n",
    "\n",
    "# Iteramos sobre el dataset:\n",
    "for post in hn:\n",
    "    longitud = len(post)\n",
    "    if longitud == 7:\n",
    "        posts_7 += 1\n",
    "    else:\n",
    "        post_no7 += 1\n",
    "\n",
    "print(f\"Hay {posts_7} elementos con 7 subelementos, y {post_no7} elementos con un número distinto de elementos\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30252e82",
   "metadata": {},
   "source": [
    "Vamos a eliminar todos los posts que no hayan sido comentados o que solo hayan sido comentados una vez. Para ello, vamos a iterar de nuevo sobre el dataset y añadiremos a una nueva lista los posts que tengan al menos un comentario.\n",
    "\n",
    "Según la cabecera, el índice 4 es el que contiene el número de comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bccbcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52346\n"
     ]
    }
   ],
   "source": [
    "HN = []\n",
    "\n",
    "for post in hn:\n",
    "    comentarios = post[4]\n",
    "    comentarios = int(comentarios)\n",
    "    if comentarios > 1:\n",
    "        HN.append(post)\n",
    "\n",
    "print(len(HN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af6b23",
   "metadata": {},
   "source": [
    "Ahora tenemos un dataset con 52.346 posts, y todos ellos han sido comentados.\n",
    "\n",
    "Lo siguiente que vamos a hacer es eliminar todos los posts que, aunque hayan sido comentados, no hayan sido puntuados. Las puntuaciones vienen reflejadas en el índice nº 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dfeda7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50289\n"
     ]
    }
   ],
   "source": [
    "h_n = []\n",
    "\n",
    "for post in HN:\n",
    "    punt = post[3]\n",
    "    punt = int(punt)\n",
    "    if punt > 1:\n",
    "        h_n.append(post)\n",
    "        \n",
    "print(len(h_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f203a3",
   "metadata": {},
   "source": [
    "Lo cual nos deja un dataset mucho más compacto y manejable de unos 50.000 elementos, habiendo descartado unos 250.000 que no nos servían."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323e2b1a",
   "metadata": {},
   "source": [
    "## Explorando los Ask HN y Show HN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29640cce",
   "metadata": {},
   "source": [
    "Tenemos un dataset (h_n) de 50.289 elementos.\n",
    "\n",
    "Vamos a imprimir las 3 primeras listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b8d4196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53'], ['12578556', 'OpenMW, Open Source Elderscrolls III: Morrowind Reimplementation', 'https://openmw.org/en/', '32', '3', 'rocky1138', '9/26/2016 1:24'], ['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17']]\n"
     ]
    }
   ],
   "source": [
    "print(h_n[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fb992d",
   "metadata": {},
   "source": [
    "Ya comentamos con anterioridad que los posts del tipo Ask HN y Show HN tienen un especial interés, y es en ellos donde vamos a focalizar nuestro estudio.\n",
    "\n",
    "Por tanto, ahora vamos a filtrar en nuestro dataset y seleccionaremos únicamente los post que empiecen con Ask HN o Show HN. Para ello, vamos a utilizar el método *startswith* .\n",
    "\n",
    "- Crearemos tres listas vacías donde irán los posts Ask HN, Show HN, y el resto de posts\n",
    "- Iteraremos sobre el dataset, para trabajar con el título (índice nº 1)\n",
    "- Con el método lower(), modificaremos los títulos a letra minúscula, evitaremos posibles errores\n",
    "- Dependiendo del post, irán a parar a una lista u otra\n",
    "- Veremos cuántos posts de cada tipo hay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "501da864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4776\n",
      "3209\n",
      "42304\n"
     ]
    }
   ],
   "source": [
    "askHN = [] # esta lista contendrá los Ask HN\n",
    "showHN = [] # esta lista contendrá los Show HN\n",
    "otros = [] # esta lista contendrá el resto de posts\n",
    "\n",
    "for post in h_n:\n",
    "    titulo = post[1]\n",
    "    titulo = titulo.lower()\n",
    "    \n",
    "    if titulo.startswith('ask hn'):\n",
    "        askHN.append(post)\n",
    "    elif titulo.startswith('show hn'):\n",
    "        showHN.append(post)\n",
    "    else:\n",
    "        otros.append(post)\n",
    "\n",
    "numASK = len(askHN)\n",
    "numSHOW = len(showHN)\n",
    "numOTROS = len(otros)\n",
    "\n",
    "print(numASK)\n",
    "print(numSHOW)\n",
    "print(numOTROS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb09cf7a",
   "metadata": {},
   "source": [
    "Vamos a mostrar los 3 primeros posts de askHN y showHN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7c8dfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53']\n",
      "['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17']\n",
      "['12577647', 'Ask HN: Someone uses stock trading as passive income?', '', '5', '2', '00taffe', '9/25/2016 21:50']\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,3):\n",
    "    print(askHN[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b23d3687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12574773', 'Show HN: Cursor that Screenshot', 'http://edward.codes/cursor-that-screenshot', '3', '3', 'ed-bit', '9/25/2016 10:50']\n",
      "['12572412', 'Show HN: G9.js  Automatically Interactive Differentiable Graphics', 'http://omrelli.ug/g9/gallery/', '215', '26', 'bijection', '9/24/2016 20:07']\n",
      "['12571200', 'Show HN: InstaPart  Build circuit boards faster with instant parts', 'http://www.snapeda.com/instapart', '301', '102', 'natashabaker', '9/24/2016 15:06']\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,3):\n",
    "    print(showHN[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f99a5",
   "metadata": {},
   "source": [
    "Vamos a determinar qué tipo de posts reciben más comentarios de media, Ask HN o Show HN.\n",
    "Los comentarios vienen reflejados en el índice nº 4 de cada elemento.\n",
    "\n",
    "Para ello utilizaremos dos contadores e iteraremos las listas que acabamos de crear (askHN, showHN):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f78f7785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los post Ask HN reciben de media 19 comentarios\n",
      "Los post Show HN reciben de media 15 comentarios\n"
     ]
    }
   ],
   "source": [
    "ask_total_com = 0\n",
    "show_total_com = 0\n",
    "\n",
    "for ask in askHN:\n",
    "    num_com = ask[4]\n",
    "    num_com = int(num_com)\n",
    "    ask_total_com += num_com\n",
    "\n",
    "for show in showHN:\n",
    "    num_com = show[4]\n",
    "    num_com = int(num_com)\n",
    "    show_total_com += num_com\n",
    "    \n",
    "# Para calcular la media, dividimos el total de comentarios entre el nº de posts (longitud de la lista)\n",
    "\n",
    "media_com_ask = round(ask_total_com / numASK)\n",
    "media_com_show = round(show_total_com / numSHOW)\n",
    "\n",
    "print(f\"Los post Ask HN reciben de media {media_com_ask} comentarios\")\n",
    "print(f\"Los post Show HN reciben de media {media_com_show} comentarios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b875e2f2",
   "metadata": {},
   "source": [
    "Como podemos observar, los post tipo Ask HN son más populares entre los usuarios, ya que reciben aproximadamente un 30% más de comentarios que los tipo Show HN.\n",
    "Hemos redondeado las medias a números enteros para verlo con más facilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63061318",
   "metadata": {},
   "source": [
    "Como los post AskHN son más populares, vamos a centrarnos en ellos.\n",
    "\n",
    "Vamos a trabajar ahora sobre la lista askHN para estudiarla más detalladamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7084b71",
   "metadata": {},
   "source": [
    "## Posts Ask HN en profundidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a12ea3",
   "metadata": {},
   "source": [
    "En este apartado trabajaremos con la lista askHN, y a modo de recapitulación, vamos a mostrar las  propiedades que ya hemos visto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "136fc768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La lista askHN contiene 4776 posts\n",
      "Los posts de askHN tienen un total de 91213 comentarios\n",
      "Los posts de askHN reciben de media 19 comentarios cada uno\n"
     ]
    }
   ],
   "source": [
    "print(f\"La lista askHN contiene {numASK} posts\")\n",
    "print(f\"Los posts de askHN tienen un total de {ask_total_com} comentarios\")\n",
    "print(f\"Los posts de askHN reciben de media {media_com_ask} comentarios cada uno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d63147",
   "metadata": {},
   "source": [
    "El último índice de cada elemento, según la cabecera del dataset, es la fecha de creación del post. Vamos a ver algunos ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41d596b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/26/2016 2:53\n",
      "9/26/2016 1:17\n",
      "9/25/2016 21:50\n"
     ]
    }
   ],
   "source": [
    "print(askHN[0][-1])\n",
    "print(askHN[1][-1])\n",
    "print(askHN[2][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a78e6a",
   "metadata": {},
   "source": [
    "Gracias a que tenemos el momento exacto de la creación del post, podemos estudiar qué posts reciben más comentarios en relación a la hora de creación del mismo.\n",
    "\n",
    "Para ello, vamos a utilizar la librería *datetime* .\n",
    "\n",
    "Antes de nada, vamos a fijarnos que las fechas del dataset vienen dadas en el siguiente formato:\n",
    "\n",
    "**mm/dd/yyyy hh:mm**\n",
    "\n",
    "Debemos convertir los strings de las fechas a objetos datetime para poder trabajar con ellos, y posteriormente veremos el número de comentarios que reciben los posts según la hora en la que fue creado.\n",
    "\n",
    "Lo haremos de la siguiente manera:\n",
    "\n",
    "- Importaremos la librería datetime\n",
    "- Construiremos una lista de resultados. Esta lista recibirá dos elementos de cada post: el número de comentarios y la hora de creación. Por lo tanto, será una lista de listas.\n",
    "- Crearemos dos diccionarios vacíos, el primero albergará el número de posts creados en cada hora, y el segundo el número de comentarios según la hora de creación de los posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1cb5dbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4776\n",
      "['9/26/2016 1:17', 3]\n",
      "['9/25/2016 21:50', 2]\n",
      "['9/25/2016 19:22', 22]\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "lista_resultados = []\n",
    "\n",
    "for post in askHN:\n",
    "    creacion = post[-1]\n",
    "    com = post[4]\n",
    "    com = int(com)\n",
    "    \n",
    "    lista_resultados.append([creacion, com])\n",
    "    \n",
    "# Imprimimos varios ejemplos para verificar que el procedimiento ha sido correcto:\n",
    "\n",
    "print(len(lista_resultados))\n",
    "print(lista_resultados[1])\n",
    "print(lista_resultados[2])\n",
    "print(lista_resultados[3])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea0f526",
   "metadata": {},
   "source": [
    "La longitud de la lista coincide con el número de posts, y tenemos una lista de listas, que es lo que queríamos.\n",
    "\n",
    "Seguimos con los diccionarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7455367a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'02': 164, '01': 163, '21': 286, '19': 274, '17': 271, '15': 296, '14': 247, '10': 155, '09': 112, '07': 118, '16': 281, '08': 138, '03': 148, '00': 166, '23': 192, '22': 197, '20': 269, '18': 311, '12': 209, '11': 179, '13': 243, '06': 121, '05': 107, '04': 129}\n",
      "{'02': 2888, '01': 1993, '21': 4297, '19': 3708, '17': 5283, '15': 18194, '14': 4731, '10': 2900, '09': 1380, '07': 1513, '16': 4211, '08': 2296, '03': 2057, '00': 2169, '23': 2150, '22': 3210, '20': 4224, '18': 4624, '12': 4133, '11': 2664, '13': 7084, '06': 1497, '05': 1746, '04': 2261}\n"
     ]
    }
   ],
   "source": [
    "post_por_hora = {} # contendrá los posts creados en cada hora del día  (posts:hora)\n",
    "com_por_hora = {} # contendrá el nº de comentarios en cada hora del día  (comentarios:hora)\n",
    "\n",
    "for lista in lista_resultados:\n",
    "    \n",
    "    comentarios = lista[1]\n",
    "    \n",
    "    fecha = lista[0]\n",
    "    fecha = dt.datetime.strptime(fecha, \"%m/%d/%Y %H:%M\")\n",
    "    \n",
    "    hora = fecha.strftime(\"%H\")\n",
    "    \n",
    "    if hora not in post_por_hora:\n",
    "        post_por_hora[hora] = 1\n",
    "        com_por_hora[hora] = comentarios\n",
    "    else:\n",
    "        post_por_hora[hora] += 1\n",
    "        com_por_hora[hora] += comentarios\n",
    "                \n",
    "print(post_por_hora)\n",
    "print(com_por_hora)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5cedf",
   "metadata": {},
   "source": [
    "Ahora tenemos los dos diccionarios confeccionados como habíamos previsto.\n",
    "\n",
    "Para facilitar las lecturas, ya que el formato actual es tedioso de leer, vamos a crear una lista que contendrá la media de comentarios por hora, ya que disponemos del número total de posts y de comentarios por hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17336399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', 13.07]\n",
      "['01', 12.23]\n",
      "['02', 17.61]\n",
      "['03', 13.9]\n",
      "['04', 17.53]\n",
      "['05', 16.32]\n",
      "['06', 12.37]\n",
      "['07', 12.82]\n",
      "['08', 16.64]\n",
      "['09', 12.32]\n",
      "['10', 18.71]\n",
      "['11', 14.88]\n",
      "['12', 19.78]\n",
      "['13', 29.15]\n",
      "['14', 19.15]\n",
      "['15', 61.47]\n",
      "['16', 14.99]\n",
      "['17', 19.49]\n",
      "['18', 14.87]\n",
      "['19', 13.53]\n",
      "['20', 15.7]\n",
      "['21', 15.02]\n",
      "['22', 16.29]\n",
      "['23', 11.2]\n"
     ]
    }
   ],
   "source": [
    "media_por_hora = []\n",
    "\n",
    "for hora in com_por_hora:\n",
    "    media_por_hora.append([hora, round(com_por_hora[hora]/post_por_hora[hora],2)])\n",
    "\n",
    "media_por_hora.sort()\n",
    "\n",
    "for i in range(len(media_por_hora)):\n",
    "    print(media_por_hora[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a41787e",
   "metadata": {},
   "source": [
    "Hemos ordenado la lista final y redondeado las medias para una mayor legibilidad, pero vamos a dejarlo aún más claro, mostrando las cinco horas con más comentarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4589acc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los posts creados a las 15h tienen una media de 61.47 comentarios\n",
      "Los posts creados a las 13h tienen una media de 29.15 comentarios\n",
      "Los posts creados a las 12h tienen una media de 19.78 comentarios\n",
      "Los posts creados a las 17h tienen una media de 19.49 comentarios\n",
      "Los posts creados a las 14h tienen una media de 19.15 comentarios\n"
     ]
    }
   ],
   "source": [
    "# Creamos una nueva lista, que será la \"inversa\" de media_por_hora:\n",
    "\n",
    "med_por_hora = []\n",
    "\n",
    "for x in media_por_hora:\n",
    "    hora = x[0]\n",
    "    com = x[1]\n",
    "    med_por_hora.append([com,hora])\n",
    "\n",
    "med_por_hora.sort() # ordenamos la lista, por defecto queda de menor a mayor\n",
    "med_por_hora.reverse() # y le damos la vuelta, así la tenemos ordenada de mayor a menor\n",
    "\n",
    "for i in range(5):\n",
    "    com = (med_por_hora[i][0])\n",
    "    hora = (med_por_hora[i][1])\n",
    "    print(f\"Los posts creados a las {hora}h tienen una media de {com} comentarios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5721bfbd",
   "metadata": {},
   "source": [
    "Las 15h es el mejor momento para escribir un post Ask HN en Hacker News son las 15h EST, que pertenece a las 21h CEST (hora de Madrid).\n",
    "\n",
    "Es el horario más comentado con mucha diferencia, concretamente el doble de la segunda hora más comentada (las 13h EST, 19h CEST). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc657e",
   "metadata": {},
   "source": [
    "## Próximos pasos\n",
    "\n",
    "- Estudio de los posts de Show HN\n",
    "- Posts más valorados\n",
    "- Conclusiones finales"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
